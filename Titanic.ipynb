{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_8FaSe13MOy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e9dd8718-24be-4c08-e0f6-89f9c9297ac2"
      },
      "source": [
        "!pip install kaggle\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0As8h5B76oA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34f0f294-dab2-4ea7-d6ad-086949146fbf"
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8P7j7Xh3ZTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"pranshulgoyal\",\"key\":\"4b6c314aafb507243d2d5305817487ee\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLvOUyWS3wXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMkpKPJd4Nh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cc7a5da-1c64-4c6c-be51-50ca0d7b4945"
      },
      "source": [
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YO0Orvw4Qlq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b8b68bf7-0408-47df-85e4-59d8e9fb2b25"
      },
      "source": [
        "!kaggle competitions download -c titanic"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "gender_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVe8FmlM4alF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc5DcsxA4hHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data  = pd.read_csv(\"/content/{/content}/competitions/titanic/train.csv\")\n",
        "test_data  = pd.read_csv(\"/content/{/content}/competitions/titanic/test.csv\")"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqP9JE0L490x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data.drop(['PassengerId','Name','Ticket','Embarked','Cabin'],axis=1)\n",
        "test_data = test_data.drop(['PassengerId','Name','Ticket','Embarked','Cabin'],axis = 1)\n"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztHWig4Z6Cas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4325e2d0-2f07-4e29-fbe7-6064adcb84fa"
      },
      "source": [
        "train_data[\"Male\"] = train_data[\"Sex\"]\n",
        "train_data[\"Female\"] = train_data[\"Sex\"]\n",
        "\n",
        "for i in range(0,train_data.shape[0]):\n",
        "  if(train_data[\"Sex\"][i] == \"male\"):\n",
        "    train_data[\"Male\"][i] = 1 \n",
        "    train_data[\"Female\"][i] = 0 \n",
        "  else:\n",
        "    train_data[\"Male\"][i] = 0 \n",
        "    train_data[\"Female\"][i] = 1 \n",
        "train_data = train_data.drop(columns=['Sex'])\n"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZXXdE4x7eia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytrain = train_data[\"Survived\"]"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfPU0qZcpN9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = train_data.drop([\"Survived\"],axis  =1)\n",
        "xtrain = xtrain.to_numpy()\n",
        "ytrain = ytrain.to_numpy()\n",
        "xtrain = xtrain.astype('float64')\n",
        "ytrain = ytrain.astype('float64')\n",
        "xtrain1 = xtrain\n",
        "xtrain[np.isnan(xtrain1).any(axis=1)] = 0\n",
        "assert not np.any(np.isnan(xtrain))\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKlrphnSsSwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a3728a4-9315-48da-ead4-8aae673f618e"
      },
      "source": [
        "xtraina = xtrain[:700]\n",
        "xtrainb = xtrain[700:]\n",
        "ytraina = ytrain[:700]\n",
        "ytrainb = ytrain[700:]\n",
        "print(xtrainb.shape)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(191, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URXPKlxWq8oM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(learning_rate):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(units= 5 ,input_shape=(7,),activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(units=7,activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(units=7,activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(units=7,activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(units=7,activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(units=7,activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(units=7,activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(units=5,activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  return model  \n"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gbr3NtassJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTZAqcQFs4i4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e96af970-5555-4ead-dbbb-b07825fb37e5"
      },
      "source": [
        "def train_model(model,epochs,batch_size):\n",
        "    history = model.fit(x = xtrain,y = ytrain,batch_size = batch_size,epochs=epochs, shuffle=True,validation_split = 0.2)\n",
        "    epochs = history.epoch\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    rmse = hist[\"accuracy\"]\n",
        "    return epochs, rmse  \n",
        "\n",
        "def plot_the_loss_curve(epochs, rmse):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, rmse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([rmse.min()*0.94, rmse.max()* 1.05])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the create_model, train_model, and plot_the_loss_curve functions.\")"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the create_model, train_model, and plot_the_loss_curve functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_rUxxDRxFPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU06gtLDs9Na",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ff1eecd-ebbc-4fcf-e06b-b9f707c8c512"
      },
      "source": [
        "learning_rate = 0.0009\n",
        "epochs = 200\n",
        "batch_size = 32\n",
        "\n",
        "my_model = create_model(learning_rate)\n",
        "epochs, rmse = train_model(my_model,epochs,batch_size)\n"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.2442 - accuracy: 0.6096 - val_loss: 0.2479 - val_accuracy: 0.6425\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.6096 - val_loss: 0.2388 - val_accuracy: 0.6425\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.6096 - val_loss: 0.2311 - val_accuracy: 0.6425\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.6096 - val_loss: 0.2232 - val_accuracy: 0.6425\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.6096 - val_loss: 0.2197 - val_accuracy: 0.6425\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.6096 - val_loss: 0.2129 - val_accuracy: 0.6425\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.6096 - val_loss: 0.2096 - val_accuracy: 0.6425\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.6096 - val_loss: 0.2081 - val_accuracy: 0.6425\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.6096 - val_loss: 0.2055 - val_accuracy: 0.6425\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.6110 - val_loss: 0.2063 - val_accuracy: 0.6983\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.6559 - val_loss: 0.2034 - val_accuracy: 0.7039\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.6587 - val_loss: 0.2024 - val_accuracy: 0.7095\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.6643 - val_loss: 0.2013 - val_accuracy: 0.6983\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.6376 - val_loss: 0.2021 - val_accuracy: 0.7095\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.6475 - val_loss: 0.2012 - val_accuracy: 0.6927\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.6531 - val_loss: 0.2003 - val_accuracy: 0.7039\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.6629 - val_loss: 0.1990 - val_accuracy: 0.6983\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.6643 - val_loss: 0.1986 - val_accuracy: 0.6872\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.6643 - val_loss: 0.1996 - val_accuracy: 0.6704\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.6685 - val_loss: 0.1963 - val_accuracy: 0.6816\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.6742 - val_loss: 0.1965 - val_accuracy: 0.6648\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.6699 - val_loss: 0.1993 - val_accuracy: 0.7207\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.6770 - val_loss: 0.1993 - val_accuracy: 0.6425\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.6798 - val_loss: 0.2019 - val_accuracy: 0.6425\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.6924 - val_loss: 0.2031 - val_accuracy: 0.6425\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.7022 - val_loss: 0.2074 - val_accuracy: 0.6425\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.6938 - val_loss: 0.2173 - val_accuracy: 0.6425\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.7149 - val_loss: 0.2172 - val_accuracy: 0.6425\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.7219 - val_loss: 0.2187 - val_accuracy: 0.6369\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.7163 - val_loss: 0.2199 - val_accuracy: 0.6369\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.7247 - val_loss: 0.2196 - val_accuracy: 0.6425\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.7275 - val_loss: 0.2214 - val_accuracy: 0.6369\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.7247 - val_loss: 0.2138 - val_accuracy: 0.6480\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.7205 - val_loss: 0.1879 - val_accuracy: 0.7263\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.7346 - val_loss: 0.1958 - val_accuracy: 0.6816\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.7219 - val_loss: 0.2000 - val_accuracy: 0.6592\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.7416 - val_loss: 0.1749 - val_accuracy: 0.7207\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.7430 - val_loss: 0.1785 - val_accuracy: 0.7151\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.7346 - val_loss: 0.1842 - val_accuracy: 0.6872\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.7430 - val_loss: 0.1909 - val_accuracy: 0.7151\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.7289 - val_loss: 0.1920 - val_accuracy: 0.7709\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.7402 - val_loss: 0.1526 - val_accuracy: 0.8212\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.7360 - val_loss: 0.1539 - val_accuracy: 0.8156\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.7388 - val_loss: 0.1451 - val_accuracy: 0.8324\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.7472 - val_loss: 0.1548 - val_accuracy: 0.8268\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7430 - val_loss: 0.1422 - val_accuracy: 0.8268\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.7360 - val_loss: 0.1465 - val_accuracy: 0.8268\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.7514 - val_loss: 0.1586 - val_accuracy: 0.8156\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.7486 - val_loss: 0.1427 - val_accuracy: 0.8212\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.7472 - val_loss: 0.1808 - val_accuracy: 0.7821\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.7500 - val_loss: 0.1561 - val_accuracy: 0.8045\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.7500 - val_loss: 0.1581 - val_accuracy: 0.7989\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.7528 - val_loss: 0.1519 - val_accuracy: 0.8156\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.7556 - val_loss: 0.1467 - val_accuracy: 0.8156\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.7430 - val_loss: 0.1408 - val_accuracy: 0.8101\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.7416 - val_loss: 0.1415 - val_accuracy: 0.8156\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.7528 - val_loss: 0.1446 - val_accuracy: 0.8212\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.7528 - val_loss: 0.1661 - val_accuracy: 0.7542\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.7430 - val_loss: 0.1365 - val_accuracy: 0.8156\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.7472 - val_loss: 0.1430 - val_accuracy: 0.8156\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.7514 - val_loss: 0.1383 - val_accuracy: 0.8212\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.7500 - val_loss: 0.1520 - val_accuracy: 0.8101\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.7542 - val_loss: 0.1371 - val_accuracy: 0.8101\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7430 - val_loss: 0.1495 - val_accuracy: 0.8101\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.7570 - val_loss: 0.1368 - val_accuracy: 0.8268\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.7528 - val_loss: 0.1504 - val_accuracy: 0.8101\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.7556 - val_loss: 0.1425 - val_accuracy: 0.7989\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7556 - val_loss: 0.1448 - val_accuracy: 0.8045\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.7472 - val_loss: 0.1449 - val_accuracy: 0.7933\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.7584 - val_loss: 0.1398 - val_accuracy: 0.8045\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.7556 - val_loss: 0.1536 - val_accuracy: 0.7989\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.7514 - val_loss: 0.1543 - val_accuracy: 0.7933\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.7626 - val_loss: 0.1773 - val_accuracy: 0.7318\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.7612 - val_loss: 0.1382 - val_accuracy: 0.8156\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.7570 - val_loss: 0.1426 - val_accuracy: 0.7989\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.7598 - val_loss: 0.1444 - val_accuracy: 0.8212\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.7514 - val_loss: 0.1421 - val_accuracy: 0.8101\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.7612 - val_loss: 0.1451 - val_accuracy: 0.7933\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.7626 - val_loss: 0.1459 - val_accuracy: 0.8045\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.7640 - val_loss: 0.1411 - val_accuracy: 0.8045\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.7711 - val_loss: 0.1398 - val_accuracy: 0.8101\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.7753 - val_loss: 0.1910 - val_accuracy: 0.6983\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.7640 - val_loss: 0.1375 - val_accuracy: 0.8101\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1680 - accuracy: 0.7654 - val_loss: 0.1415 - val_accuracy: 0.8101\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.7612 - val_loss: 0.1404 - val_accuracy: 0.8101\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.7598 - val_loss: 0.1651 - val_accuracy: 0.7598\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.7584 - val_loss: 0.1364 - val_accuracy: 0.8156\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.7654 - val_loss: 0.1360 - val_accuracy: 0.8324\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1704 - accuracy: 0.7640 - val_loss: 0.1450 - val_accuracy: 0.8324\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.7542 - val_loss: 0.1353 - val_accuracy: 0.8045\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.7697 - val_loss: 0.1387 - val_accuracy: 0.8268\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.7654 - val_loss: 0.1334 - val_accuracy: 0.8156\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.7598 - val_loss: 0.1398 - val_accuracy: 0.8212\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.7640 - val_loss: 0.1431 - val_accuracy: 0.8101\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1675 - accuracy: 0.7584 - val_loss: 0.1340 - val_accuracy: 0.8156\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.7683 - val_loss: 0.1525 - val_accuracy: 0.8101\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1697 - accuracy: 0.7697 - val_loss: 0.1357 - val_accuracy: 0.8156\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.7654 - val_loss: 0.1352 - val_accuracy: 0.8156\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.7570 - val_loss: 0.1386 - val_accuracy: 0.8268\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.7669 - val_loss: 0.1462 - val_accuracy: 0.8324\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.7626 - val_loss: 0.1509 - val_accuracy: 0.7877\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.7584 - val_loss: 0.1402 - val_accuracy: 0.8101\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.7654 - val_loss: 0.1441 - val_accuracy: 0.8156\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1713 - accuracy: 0.7683 - val_loss: 0.1601 - val_accuracy: 0.7933\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.7767 - val_loss: 0.1406 - val_accuracy: 0.8101\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.7725 - val_loss: 0.1356 - val_accuracy: 0.8156\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.7556 - val_loss: 0.1786 - val_accuracy: 0.7318\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.7640 - val_loss: 0.1360 - val_accuracy: 0.8212\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.7683 - val_loss: 0.1364 - val_accuracy: 0.8324\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.7584 - val_loss: 0.1322 - val_accuracy: 0.8156\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.7654 - val_loss: 0.1302 - val_accuracy: 0.8045\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.7612 - val_loss: 0.1336 - val_accuracy: 0.8212\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.7654 - val_loss: 0.1369 - val_accuracy: 0.8156\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1680 - accuracy: 0.7711 - val_loss: 0.1382 - val_accuracy: 0.8101\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.7697 - val_loss: 0.1373 - val_accuracy: 0.8212\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.7570 - val_loss: 0.1632 - val_accuracy: 0.7709\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.7598 - val_loss: 0.1367 - val_accuracy: 0.8101\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.7640 - val_loss: 0.1430 - val_accuracy: 0.8212\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.7767 - val_loss: 0.1347 - val_accuracy: 0.8212\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.7753 - val_loss: 0.1392 - val_accuracy: 0.8436\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.7697 - val_loss: 0.1493 - val_accuracy: 0.7933\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.7669 - val_loss: 0.1337 - val_accuracy: 0.8212\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.7542 - val_loss: 0.1337 - val_accuracy: 0.8324\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.7669 - val_loss: 0.1281 - val_accuracy: 0.8268\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1698 - accuracy: 0.7669 - val_loss: 0.1304 - val_accuracy: 0.8324\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.7725 - val_loss: 0.1385 - val_accuracy: 0.8156\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.7711 - val_loss: 0.1396 - val_accuracy: 0.8268\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 0.7753 - val_loss: 0.1379 - val_accuracy: 0.8212\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.7669 - val_loss: 0.1445 - val_accuracy: 0.8212\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.7795 - val_loss: 0.1289 - val_accuracy: 0.8156\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.7697 - val_loss: 0.1354 - val_accuracy: 0.8324\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.7711 - val_loss: 0.1306 - val_accuracy: 0.8268\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.7725 - val_loss: 0.1342 - val_accuracy: 0.8268\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.7711 - val_loss: 0.1278 - val_accuracy: 0.8268\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1608 - accuracy: 0.7781 - val_loss: 0.1276 - val_accuracy: 0.8380\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.7683 - val_loss: 0.1672 - val_accuracy: 0.7989\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1608 - accuracy: 0.7654 - val_loss: 0.1568 - val_accuracy: 0.7765\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.7697 - val_loss: 0.1283 - val_accuracy: 0.8380\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.7795 - val_loss: 0.1413 - val_accuracy: 0.8156\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.7711 - val_loss: 0.1378 - val_accuracy: 0.7989\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.7739 - val_loss: 0.1244 - val_accuracy: 0.8268\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1689 - accuracy: 0.7683 - val_loss: 0.1556 - val_accuracy: 0.7933\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.7697 - val_loss: 0.1372 - val_accuracy: 0.8268\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.7739 - val_loss: 0.1352 - val_accuracy: 0.8268\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.7669 - val_loss: 0.1356 - val_accuracy: 0.8268\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.7654 - val_loss: 0.1274 - val_accuracy: 0.8380\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.7781 - val_loss: 0.1364 - val_accuracy: 0.8045\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.7683 - val_loss: 0.1304 - val_accuracy: 0.8380\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1662 - accuracy: 0.7654 - val_loss: 0.1289 - val_accuracy: 0.8101\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.7739 - val_loss: 0.1367 - val_accuracy: 0.8101\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.7640 - val_loss: 0.1348 - val_accuracy: 0.8212\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.7753 - val_loss: 0.1850 - val_accuracy: 0.7151\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.7711 - val_loss: 0.1484 - val_accuracy: 0.7765\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.7725 - val_loss: 0.1333 - val_accuracy: 0.8268\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.7739 - val_loss: 0.1326 - val_accuracy: 0.8101\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.7781 - val_loss: 0.1342 - val_accuracy: 0.8268\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 0.7654 - val_loss: 0.1668 - val_accuracy: 0.7598\n",
            "Epoch 158/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1662 - accuracy: 0.7640 - val_loss: 0.1413 - val_accuracy: 0.7933\n",
            "Epoch 159/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.7781 - val_loss: 0.1346 - val_accuracy: 0.8268\n",
            "Epoch 160/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.7528 - val_loss: 0.2010 - val_accuracy: 0.6872\n",
            "Epoch 161/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.7500 - val_loss: 0.1348 - val_accuracy: 0.8045\n",
            "Epoch 162/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.7626 - val_loss: 0.1296 - val_accuracy: 0.8268\n",
            "Epoch 163/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.7711 - val_loss: 0.1339 - val_accuracy: 0.8380\n",
            "Epoch 164/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.7781 - val_loss: 0.1232 - val_accuracy: 0.8268\n",
            "Epoch 165/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.7739 - val_loss: 0.1256 - val_accuracy: 0.8380\n",
            "Epoch 166/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.7697 - val_loss: 0.1394 - val_accuracy: 0.8045\n",
            "Epoch 167/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7809 - val_loss: 0.1250 - val_accuracy: 0.8324\n",
            "Epoch 168/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.7767 - val_loss: 0.1278 - val_accuracy: 0.8380\n",
            "Epoch 169/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.7640 - val_loss: 0.1273 - val_accuracy: 0.8436\n",
            "Epoch 170/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.7626 - val_loss: 0.1308 - val_accuracy: 0.8380\n",
            "Epoch 171/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1677 - accuracy: 0.7556 - val_loss: 0.1261 - val_accuracy: 0.8380\n",
            "Epoch 172/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.7753 - val_loss: 0.1479 - val_accuracy: 0.7821\n",
            "Epoch 173/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.7781 - val_loss: 0.1366 - val_accuracy: 0.8268\n",
            "Epoch 174/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.7640 - val_loss: 0.1344 - val_accuracy: 0.8268\n",
            "Epoch 175/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1576 - accuracy: 0.7823 - val_loss: 0.1404 - val_accuracy: 0.7989\n",
            "Epoch 176/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.7809 - val_loss: 0.1263 - val_accuracy: 0.8492\n",
            "Epoch 177/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.7739 - val_loss: 0.1552 - val_accuracy: 0.8101\n",
            "Epoch 178/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.7809 - val_loss: 0.1295 - val_accuracy: 0.8380\n",
            "Epoch 179/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.7683 - val_loss: 0.1493 - val_accuracy: 0.8156\n",
            "Epoch 180/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.7654 - val_loss: 0.1540 - val_accuracy: 0.7821\n",
            "Epoch 181/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.7753 - val_loss: 0.1394 - val_accuracy: 0.8436\n",
            "Epoch 182/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.7584 - val_loss: 0.1465 - val_accuracy: 0.8101\n",
            "Epoch 183/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.7781 - val_loss: 0.1523 - val_accuracy: 0.7765\n",
            "Epoch 184/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.7823 - val_loss: 0.1295 - val_accuracy: 0.8436\n",
            "Epoch 185/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.7697 - val_loss: 0.1426 - val_accuracy: 0.8101\n",
            "Epoch 186/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.7795 - val_loss: 0.1407 - val_accuracy: 0.8324\n",
            "Epoch 187/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.7753 - val_loss: 0.1300 - val_accuracy: 0.8212\n",
            "Epoch 188/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1555 - accuracy: 0.7767 - val_loss: 0.1302 - val_accuracy: 0.8324\n",
            "Epoch 189/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.7683 - val_loss: 0.1361 - val_accuracy: 0.8101\n",
            "Epoch 190/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.7795 - val_loss: 0.1387 - val_accuracy: 0.8045\n",
            "Epoch 191/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.7795 - val_loss: 0.1343 - val_accuracy: 0.8380\n",
            "Epoch 192/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.7725 - val_loss: 0.1554 - val_accuracy: 0.7709\n",
            "Epoch 193/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.7669 - val_loss: 0.1505 - val_accuracy: 0.7877\n",
            "Epoch 194/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.7767 - val_loss: 0.1271 - val_accuracy: 0.8380\n",
            "Epoch 195/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.7697 - val_loss: 0.1319 - val_accuracy: 0.8268\n",
            "Epoch 196/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.7809 - val_loss: 0.1335 - val_accuracy: 0.8268\n",
            "Epoch 197/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1601 - accuracy: 0.7767 - val_loss: 0.1336 - val_accuracy: 0.8268\n",
            "Epoch 198/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.7725 - val_loss: 0.1351 - val_accuracy: 0.8156\n",
            "Epoch 199/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.7739 - val_loss: 0.1616 - val_accuracy: 0.7542\n",
            "Epoch 200/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.7851 - val_loss: 0.1406 - val_accuracy: 0.8268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLqXuMvvvC8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "2a867591-6026-4238-a3ac-e5bba378b261"
      },
      "source": [
        "plot_the_loss_curve(epochs,rmse)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZN5NbLYv9Ty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e8192ac2-4d55-4530-bd01-a38689b0085f"
      },
      "source": [
        "test_data[\"Male\"] = test_data[\"Sex\"]\n",
        "test_data[\"Female\"] = test_data[\"Sex\"]\n",
        "\n",
        "for i in range(0,test_data.shape[0]):\n",
        "  if(test_data[\"Sex\"][i] == \"male\"):\n",
        "    test_data[\"Male\"][i] = 1 \n",
        "    test_data[\"Female\"][i] = 0 \n",
        "  else:\n",
        "    test_data[\"Male\"][i] = 0 \n",
        "    test_data[\"Female\"][i] = 1 \n",
        "test_data = test_data.drop(columns=['Sex'])\n",
        "xtest = test_data.to_numpy()\n",
        "xtest = xtest.astype('float64')\n",
        "xtest1 = xtest\n",
        "xtest[np.isnan(xtest1).any(axis=1)] = 0\n",
        "assert not np.any(np.isnan(xtest))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcM9jLSG15s9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = my_model.predict(xtest)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhQ_d4PNwpI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,predict.shape[0]):\n",
        "  if predict[i] > 0.6:\n",
        "    predict[i] = 1\n",
        "  else:\n",
        "    predict[i] = 0\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsSOffv7zHYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = predict.astype('int32')"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEhVRwO50Hxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = pd.DataFrame(predict,columns=[\"Survived\"])"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47quBX6M0JjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_data  = pd.read_csv(\"/content/{/content}/competitions/titanic/test.csv\")"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b93iOWjF0pK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = pd.DataFrame(Test_data[\"PassengerId\"],columns=[\"PassengerId\"])"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aut5os4K0tNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final[\"Survived\"] = predict[\"Survived\"]"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVCFI68r09d1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7c0c7e56-af51-48a4-9174-415f64290439"
      },
      "source": [
        "final.head"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of      PassengerId  Survived\n",
              "0            892         0\n",
              "1            893         1\n",
              "2            894         0\n",
              "3            895         0\n",
              "4            896         0\n",
              "..           ...       ...\n",
              "413         1305         0\n",
              "414         1306         1\n",
              "415         1307         0\n",
              "416         1308         0\n",
              "417         1309         0\n",
              "\n",
              "[418 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fYc-0Ej0_le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final.to_csv (r'submission.csv', index = False, header=True)"
      ],
      "execution_count": 140,
      "outputs": []
    }
  ]
}